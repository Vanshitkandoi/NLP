{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31564073",
   "metadata": {},
   "source": [
    "## 22-12-22 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e5005d",
   "metadata": {},
   "source": [
    "## Sentence Toke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af078eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4cdc3781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'is': 3, 'language': 2, 'of': 2, 'a': 2, 'to': 2, 'as': 2, 'Natural': 1, 'processing': 1, '(NLP)': 1, 'the': 1, ...})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Frequency Distribution of Words\n",
    "txt1 = \"Natural language processing (NLP) is the ability of a computer program to understand human language as it is spoken and written -- referred to as natural language. It is a component of artificial intelligence (AI).\"\n",
    "fd = nltk.FreqDist(txt1.split())\n",
    "fd\n",
    "# print(fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ddc5872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.probability import ConditionalFreqDist\n",
    "cfd = ConditionalFreqDistreqDist((len(word),word) for word in txt1.split())\n",
    "cfd[4] # gives you 4 words "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e593dc6a",
   "metadata": {},
   "source": [
    "## HW : To determine Frequency Distribution and Conditional Frequency Distribution of any one of the Presential inaugural address (nouns-> business not adjectives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40ac8602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'to': 9, 'as': 4, 'a': 4, 'have': 4, 'computers': 3, 'language': 3, 'humans': 3, 'the': 3, 'process': 3, 'and': 3, ...})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt2 = \"NLP enables computers to understand natural language as humans do. Whether the language is spoken or written, natural language processing uses artificial intelligence to take real-world input, process it, and make sense of it in a way a computer can understand. Just as humans have different sensors -- such as ears to hear and eyes to see -- computers have programs to read and microphones to collect audio. And just as humans have a brain to process that input, computers have a program to process their respective inputs. At some point in processing, the input is converted to code that the computer can understand.\"\n",
    "fd = nltk.FreqDist(txt2.split())\n",
    "fd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "695faf4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'have': 4, 'that': 2, 'uses': 1, 'take': 1, 'make': 1, 'Just': 1, 'such': 1, 'ears': 1, 'hear': 1, 'eyes': 1, ...})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfd = ConditionalFreqDist((len(word),word) for word in txt2.split())\n",
    "cfd[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28c3de3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jieba\n",
      "  Downloading jieba-0.42.1.tar.gz (19.2 MB)\n",
      "Building wheels for collected packages: jieba\n",
      "  Building wheel for jieba (setup.py): started\n",
      "  Building wheel for jieba (setup.py): finished with status 'done'\n",
      "  Created wheel for jieba: filename=jieba-0.42.1-py3-none-any.whl size=19314476 sha256=7d796cb044c0b199a06bdc4e9d6384ee15dbdf41045958f8e9b5973afbdefca6\n",
      "  Stored in directory: c:\\users\\vansh\\appdata\\local\\pip\\cache\\wheels\\ca\\38\\d8\\dfdfe73bec1d12026b30cb7ce8da650f3f0ea2cf155ea018ae\n",
      "Successfully built jieba\n",
      "Installing collected packages: jieba\n",
      "Successfully installed jieba-0.42.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip install jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f95d4aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache C:\\Users\\vansh\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.830 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "《 嘉定 屠城 紀 略 》 影印 影印本 印本 重 複\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "seg = jieba.cut(\"《嘉定屠城紀略》影印本重複\", cut_all = True)\n",
    "print(\" \".join(seg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "445d8ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Become', 'an', 'expert', 'in', 'NLP']\n"
     ]
    }
   ],
   "source": [
    "# BASIC TEXT PROCESSING PIPELINE\n",
    "import nltk\n",
    "sent = \"Become an expert in NLP\"\n",
    "words = nltk.word_tokenize(sent) # Splitting of words (same as splitting)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6bd76e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Businesses', 'use', 'massive', 'quantities', 'of', 'unstructured', ',', 'text-heavy', 'data', 'and', 'need', 'a', 'way', 'to', 'efficiently', 'process', 'it', '.']\n",
      "\n",
      "[('Businesses', 'NNS'), ('use', 'VBP'), ('massive', 'JJ'), ('quantities', 'NNS'), ('of', 'IN'), ('unstructured', 'JJ'), (',', ','), ('text-heavy', 'JJ'), ('data', 'NNS'), ('and', 'CC'), ('need', 'VB'), ('a', 'DT'), ('way', 'NN'), ('to', 'TO'), ('efficiently', 'RB'), ('process', 'VB'), ('it', 'PRP'), ('.', '.')]\n",
      "\n",
      "\n",
      "['A', 'lot', 'of', 'the', 'information', 'created', 'online', 'and', 'stored', 'in', 'databases', 'is', 'natural', 'human', 'language', ',', 'and', 'until', 'recently', ',', 'businesses', 'could', 'not', 'effectively', 'analyze', 'this', 'data', '.']\n",
      "\n",
      "[('A', 'DT'), ('lot', 'NN'), ('of', 'IN'), ('the', 'DT'), ('information', 'NN'), ('created', 'VBD'), ('online', 'NN'), ('and', 'CC'), ('stored', 'VBN'), ('in', 'IN'), ('databases', 'NNS'), ('is', 'VBZ'), ('natural', 'JJ'), ('human', 'JJ'), ('language', 'NN'), (',', ','), ('and', 'CC'), ('until', 'IN'), ('recently', 'RB'), (',', ','), ('businesses', 'NNS'), ('could', 'MD'), ('not', 'RB'), ('effectively', 'RB'), ('analyze', 'VBP'), ('this', 'DT'), ('data', 'NN'), ('.', '.')]\n",
      "\n",
      "\n",
      "['This', 'is', 'where', 'natural', 'language', 'processing', 'is', 'useful', '.']\n",
      "\n",
      "[('This', 'DT'), ('is', 'VBZ'), ('where', 'WRB'), ('natural', 'JJ'), ('language', 'NN'), ('processing', 'NN'), ('is', 'VBZ'), ('useful', 'JJ'), ('.', '.')]\n",
      "\n",
      "\n",
      "['The', 'advantage', 'of', 'natural', 'language', 'processing', 'can', 'be', 'seen', 'when', 'considering', 'the', 'following', 'two', 'statements', ':', '``', 'Cloud', 'computing', 'insurance', 'should', 'be', 'part', 'of', 'every', 'service-level', 'agreement', ',', \"''\", 'and', ',', '``', 'A', 'good', 'SLA', 'ensures', 'an', 'easier', 'night', \"'s\", 'sleep', '--', 'even', 'in', 'the', 'cloud', '.', \"''\"]\n",
      "\n",
      "[('The', 'DT'), ('advantage', 'NN'), ('of', 'IN'), ('natural', 'JJ'), ('language', 'NN'), ('processing', 'NN'), ('can', 'MD'), ('be', 'VB'), ('seen', 'VBN'), ('when', 'WRB'), ('considering', 'VBG'), ('the', 'DT'), ('following', 'VBG'), ('two', 'CD'), ('statements', 'NNS'), (':', ':'), ('``', '``'), ('Cloud', 'NNP'), ('computing', 'VBG'), ('insurance', 'NN'), ('should', 'MD'), ('be', 'VB'), ('part', 'NN'), ('of', 'IN'), ('every', 'DT'), ('service-level', 'JJ'), ('agreement', 'NN'), (',', ','), (\"''\", \"''\"), ('and', 'CC'), (',', ','), ('``', '``'), ('A', 'DT'), ('good', 'JJ'), ('SLA', 'NNP'), ('ensures', 'VBZ'), ('an', 'DT'), ('easier', 'JJR'), ('night', 'NN'), (\"'s\", 'POS'), ('sleep', 'NN'), ('--', ':'), ('even', 'RB'), ('in', 'IN'), ('the', 'DT'), ('cloud', 'NN'), ('.', '.'), (\"''\", \"''\")]\n",
      "\n",
      "\n",
      "['If', 'a', 'user', 'relies', 'on', 'natural', 'language', 'processing', 'for', 'search', ',', 'the', 'program', 'will', 'recognize', 'that', 'cloud', 'computing', 'is', 'an', 'entity', ',', 'that', 'cloud', 'is', 'an', 'abbreviated', 'form', 'of', 'cloud', 'computing', 'and', 'that', 'SLA', 'is', 'an', 'industry', 'acronym', 'for', 'service-level', 'agreement', '.']\n",
      "\n",
      "[('If', 'IN'), ('a', 'DT'), ('user', 'NN'), ('relies', 'VBZ'), ('on', 'IN'), ('natural', 'JJ'), ('language', 'NN'), ('processing', 'NN'), ('for', 'IN'), ('search', 'NN'), (',', ','), ('the', 'DT'), ('program', 'NN'), ('will', 'MD'), ('recognize', 'VB'), ('that', 'IN'), ('cloud', 'NN'), ('computing', 'NN'), ('is', 'VBZ'), ('an', 'DT'), ('entity', 'NN'), (',', ','), ('that', 'IN'), ('cloud', 'NN'), ('is', 'VBZ'), ('an', 'DT'), ('abbreviated', 'JJ'), ('form', 'NN'), ('of', 'IN'), ('cloud', 'NN'), ('computing', 'NN'), ('and', 'CC'), ('that', 'DT'), ('SLA', 'NNP'), ('is', 'VBZ'), ('an', 'DT'), ('industry', 'NN'), ('acronym', 'NN'), ('for', 'IN'), ('service-level', 'JJ'), ('agreement', 'NN'), ('.', '.')]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "texts = [\"\"\"Businesses use massive quantities of unstructured, text-heavy data and need a way to efficiently process it. A lot of the information created online and stored in databases is natural human language, and until recently, businesses could not effectively analyze this data. This is where natural language processing is useful.\n",
    "The advantage of natural language processing can be seen when considering the following two statements: \"Cloud computing insurance should be part of every service-level agreement,\" and, \"A good SLA ensures an easier night's sleep -- even in the cloud.\" If a user relies on natural language processing for search, the program will recognize that cloud computing is an entity, that cloud is an abbreviated form of cloud computing and that SLA is an industry acronym for service-level agreement.\"\"\"]\n",
    "\n",
    "for text in texts:\n",
    "    sentences = nltk.sent_tokenize(text) # tokenize sentence\n",
    "    for sentence in sentences:\n",
    "        words = nltk.word_tokenize(sentence) # tokenize words in each sentence\n",
    "        print(words)\n",
    "        print()\n",
    "        tagged = nltk.pos_tag(words)\n",
    "        print(tagged)\n",
    "        print()\n",
    "        print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
