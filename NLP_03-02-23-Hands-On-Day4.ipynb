{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68ea5377",
   "metadata": {},
   "source": [
    "## Date: 03-02-2023 - 20BCE2667\n",
    "# Topic: Stemming of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "154868d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib import request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0edc5bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.gutenberg.org/files/98/98-0.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f360bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = request.urlopen(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ea40c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = response.read().decode('utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e2a2a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fedfd10b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\ufeffThe', 'Project', 'Gutenberg', 'eBook', 'of', 'A', 'Tale', 'of', 'Two', 'Cities', ',', 'by', 'Charles', 'Dickens', 'This', 'eBook', 'is', 'for', 'the', 'use', 'of', 'anyone', 'anywhere', 'in', 'the', 'United', 'States', 'and', 'most', 'other', 'parts', 'of', 'the', 'world', 'at', 'no', 'cost', 'and', 'with', 'almost', 'no', 'restrictions', 'whatsoever', '.', 'You', 'may', 'copy', 'it', ',', 'give', 'it', 'away', 'or', 're-use', 'it', 'under', 'the', 'terms', 'of', 'the', 'Project', 'Gutenberg', 'License', 'included', 'with', 'this', 'eBook', 'or', 'online', 'at', 'www.gutenberg.org', '.', 'If', 'you', 'are', 'not', 'located', 'in', 'the', 'United', 'States', ',', 'you', 'will', 'have', 'to', 'check', 'the', 'laws', 'of', 'the', 'country', 'where', 'you', 'are', 'located', 'before', 'using', 'this', 'eBook', '.', 'Title', ':', 'A', 'Tale', 'of', 'Two', 'Cities', 'A', 'Story', 'of', 'the', 'French', 'Revolution', 'Author', ':', 'Charles', 'Dickens', 'Release', 'Date', ':', 'January', ',', '1994', '[', 'eBook', '#', '98', ']', '[', 'Most', 'recently', 'updated', ':', 'December', '20', ',', '2020', ']', 'Language', ':', 'English', 'Character', 'set', 'encoding', ':', 'UTF-8', 'Produced', 'by', ':', 'Judith', 'Boss', 'and', 'David', 'Widger', '*', '*', '*', 'START', 'OF', 'THE', 'PROJECT', 'GUTENBERG', 'EBOOK', 'A', 'TALE', 'OF', 'TWO', 'CITIES', '*', '*', '*', 'A', 'TALE', 'OF', 'TWO', 'CITIES', 'A', 'STORY', 'OF', 'THE', 'FRENCH', 'REVOLUTION', 'By', 'Charles', 'Dickens', 'CONTENTS', 'Book', 'the', 'First', '--', 'Recalled', 'to', 'Life', 'CHAPTER', 'I', 'The', 'Period', 'CHAPTER', 'II']\n"
     ]
    }
   ],
   "source": [
    "print(tokens[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d21585a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BeautifulSoup\n",
    "# Peprocessing - RE to clean any html tags of\n",
    "# PoS Tagging\n",
    "# !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85787c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "happi\n",
      "joyou\n",
      "cacti\n",
      "sing\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "porter = PorterStemmer()\n",
    "print(porter.stem('happiness'))\n",
    "print(porter.stem('joyous'))\n",
    "print(porter.stem('cacti'))\n",
    "print(porter.stem('singing'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6cde12dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "happy\n",
      "joy\n",
      "cact\n",
      "sing\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import LancasterStemmer\n",
    "lancaster = LancasterStemmer()\n",
    "print(lancaster.stem('happiness'))\n",
    "print(lancaster.stem('joyous'))\n",
    "print(lancaster.stem('cacti'))\n",
    "print(lancaster.stem('singing'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d18c4611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "walk\n",
      "s -> Error \n",
      "\n",
      "sing\n",
      "s -> Error\n",
      "p -> Error\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import RegexpStemmer\n",
    "regexp = RegexpStemmer('ing')\n",
    "print(regexp.stem('walking'))\n",
    "print(regexp.stem('singing'), \"-> Error\", \"\\n\")\n",
    "\n",
    "regexp = RegexpStemmer('ing$')\n",
    "print(regexp.stem('singing'))\n",
    "print(regexp.stem('sing'), \"-> Error\")\n",
    "print(regexp.stem('ping'), \"-> Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dccf5aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mang\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import SnowballStemmer\n",
    "snowball = SnowballStemmer('french')\n",
    "print(snowball.stem('manges'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "83eaa6b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class SnowballStemmer in module nltk.stem.snowball:\n",
      "\n",
      "class SnowballStemmer(nltk.stem.api.StemmerI)\n",
      " |  SnowballStemmer(language, ignore_stopwords=False)\n",
      " |  \n",
      " |  Snowball Stemmer\n",
      " |  \n",
      " |  The following languages are supported:\n",
      " |  Arabic, Danish, Dutch, English, Finnish, French, German,\n",
      " |  Hungarian, Italian, Norwegian, Portuguese, Romanian, Russian,\n",
      " |  Spanish and Swedish.\n",
      " |  \n",
      " |  The algorithm for English is documented here:\n",
      " |  \n",
      " |      Porter, M. \"An algorithm for suffix stripping.\"\n",
      " |      Program 14.3 (1980): 130-137.\n",
      " |  \n",
      " |  The algorithms have been developed by Martin Porter.\n",
      " |  These stemmers are called Snowball, because Porter created\n",
      " |  a programming language with this name for creating\n",
      " |  new stemming algorithms. There is more information available\n",
      " |  at http://snowball.tartarus.org/\n",
      " |  \n",
      " |  The stemmer is invoked as shown below:\n",
      " |  \n",
      " |  >>> from nltk.stem import SnowballStemmer\n",
      " |  >>> print(\" \".join(SnowballStemmer.languages)) # See which languages are supported\n",
      " |  arabic danish dutch english finnish french german hungarian\n",
      " |  italian norwegian porter portuguese romanian russian\n",
      " |  spanish swedish\n",
      " |  >>> stemmer = SnowballStemmer(\"german\") # Choose a language\n",
      " |  >>> stemmer.stem(\"Autobahnen\") # Stem a word\n",
      " |  'autobahn'\n",
      " |  \n",
      " |  Invoking the stemmers that way is useful if you do not know the\n",
      " |  language to be stemmed at runtime. Alternatively, if you already know\n",
      " |  the language, then you can invoke the language specific stemmer directly:\n",
      " |  \n",
      " |  >>> from nltk.stem.snowball import GermanStemmer\n",
      " |  >>> stemmer = GermanStemmer()\n",
      " |  >>> stemmer.stem(\"Autobahnen\")\n",
      " |  'autobahn'\n",
      " |  \n",
      " |  :param language: The language whose subclass is instantiated.\n",
      " |  :type language: str or unicode\n",
      " |  :param ignore_stopwords: If set to True, stopwords are\n",
      " |                           not stemmed and returned unchanged.\n",
      " |                           Set to False by default.\n",
      " |  :type ignore_stopwords: bool\n",
      " |  :raise ValueError: If there is no stemmer for the specified\n",
      " |                         language, a ValueError is raised.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      SnowballStemmer\n",
      " |      nltk.stem.api.StemmerI\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, language, ignore_stopwords=False)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  stem(self, token)\n",
      " |      Strip affixes from the token and return the stem.\n",
      " |      \n",
      " |      :param token: The token that should be stemmed.\n",
      " |      :type token: str\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  languages = ('arabic', 'danish', 'dutch', 'english', 'finnish', 'frenc...\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from nltk.stem.api.StemmerI:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(SnowballStemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ef54cafc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['there', 'wa', 'a', 'steam', 'mist', 'in', 'all', 'the', 'hollows,', 'and', 'it', 'had', 'roam', 'in', 'it', 'forlorn', 'up', 'the', 'hill,', 'like', 'an', 'evil', 'spirit,', 'seek', 'rest', 'and', 'find', 'none.', 'a', 'clammi', 'and', 'intens', 'cold', 'mist,', 'it', 'made', 'it', 'slow', 'way', 'through', 'the', 'air', 'in', 'rippl', 'that', 'visibl', 'follow', 'and', 'overspread', 'one', 'another,', 'as', 'the', 'wave', 'of', 'an', 'unwholesom', 'sea', 'might', 'do.', 'it', 'wa', 'dens', 'enough', 'to', 'shut', 'out', 'everyth', 'from', 'the', 'light', 'of', 'the', 'coach-lamp', 'but', 'these', 'it', 'own', 'workings,', 'and', 'a', 'few', 'yard', 'of', 'road;', 'and', 'the', 'reek', 'of', 'the', 'labour', 'hors', 'steam', 'into', 'it,', 'as', 'if', 'they', 'had', 'made', 'it', 'all.']\n"
     ]
    }
   ],
   "source": [
    "l = []\n",
    "text = \"\"\"There was a steaming mist in all the hollows, and it had roamed in its forlornness up the hill, like an evil spirit, seeking rest and finding none. A clammy and intensely cold mist, it made its slow way through the air in ripples that visibly followed and overspread one another, as the waves of an unwholesome sea might do. It was dense enough to shut out everything from the light of the coach-lamps but these its own workings, and a few yards of road; and the reek of the labouring horses steamed into it, as if they had made it all.\"\"\"\n",
    "stemmed = [porter.stem(token) for token in text.split(\" \")] \n",
    "print(stemmed)\n",
    "# for i in tokens:\n",
    "#     l.append(porter.stem(i))\n",
    "# print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b6ed134d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cactus\n",
      "mouse\n",
      "be\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemma = WordNetLemmatizer()\n",
    "print(lemma.lemmatize(\"cacti\"))\n",
    "print(lemma.lemmatize(\"mice\"))\n",
    "print(lemma.lemmatize(\"am\", pos = 'v'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
